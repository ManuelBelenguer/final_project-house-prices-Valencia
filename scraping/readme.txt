One of the main motivations on creating this project was to use as many skills gained during the bootcamp at Ironhack as possible. That's why instead of choosing a location that might have a dataset ready I chose the city of Valencia, so the dataset used in the project it's a dataset gotten using web scraping techniques. 

The web page I decided to scrape due to the very little difficulties regarding data extraction was "pisos.com". I tried to scrape some other webpages with no success: "Idealista.com", "Zoopla.com", "Fotocasa.com". Choosing "Pisos.com" was easier when aquiring the data, but the quality of the data and the amount of data that I was able to get was not as good as if Idealista or Fotocasa were scraped. 

-< Minimum Objective Variables >-

        - Address
        - Neighbourhood
        - District
        - Square Meters Living Surface
        - Number of bedrooms
        - Number of bathrooms
        - Price (dependent variable)
        
        
A different dataset was stored for each of the pages scraped, then all these datasets wil be merged into one.


Note: this is the first project involving real scraping that I ever performed so the quality of the data is not the best. Modifications on the ways of how to get the data will be made in order the achieve better results when building our model. 